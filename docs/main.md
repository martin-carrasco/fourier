# On the convolution and the Fourier Transform

## Introduction

>> "The Fourier Transform is one of the secrets of the universe [something like that]" (Brad Osgood, on The Fourier Transform and its applications)

The words of Osgood, a teacher of Stanford Electronics, perfectly depicts the feeling when one understands the Fourier Transform and, subsequently, its importance. One of the main disadvantages of this fact is that there's not just one way to understand it. The common intuition lies in the fact that one can model any function by a weighted summation of sinusoids, and without considering the reason behind it, it makes sense. But the first question one asks himself is: why? 

Another way to address it is stating that such transform allows a function to be mapped from the spatial/time domain to the frequency. Again, it makes perfect sense, but why?

There are many areas of knowledge that try to apply the Fourier Transform to their specific interests and that results in a variety of insights, explanations and focuses. We've leaned towards the algebraic viewpoint of the matter, but we'll try to include proofs and other interpretations (geometric, for example) when it's necessary.

We'll first revise all the mathematical concepts necessary to understand Fourier. Starting from a simple analogy and the derivation of the Fourier Transform in the continuous realm, we'll continue to the discrete realm and then finish in it's computation. In Related Works, we'll discuss some other algorithms for computing the Discrete Fourier Transform and describe some of the ways it is applied in the real world. Then, two seemingly unrelated applications will be described in Proposal and their evaluation will follow. Finally, our conclusions will define some new scopes in which the key idea of this work can be extended.

## Background

### The intuition

Back in freshman years, there was a seemingly benign concept of vectors. Their usual representation was a simple 2D column matrix containing the elements that described it in both the x and y axis or an equivalent decomposition of those elements with the help of two other vectors, usually denoted by $\hat{i}$ and $\hat{j}$. At first, the choice of those two vectors appeared to be sort of arbitrary and in a way it was. One could choose any set of basis vectors $\{b_i\}$ as long as two were independent. The idea is further developed with the introduction of eigenvectors.



## Related Works

## Proposal and application

## Evaluation 

## Conclusions and Further Research
